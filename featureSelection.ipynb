{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection is an important step in data preprocessing that involves selecting a subset of relevant features or variables from a larger set of features.we will eliminate features that can be noisy  with misleading data, this process is crucial in reducing the complexity of a machine learning model and improving its performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,precision_score,confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing training and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv(\"data/balancedAppDarknet.csv\")\n",
    "dfValidate = pd.read_csv(\"data/validation_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping useless or duplicate columns :\n",
    "### Based on domain knwoledge we can clearly see that some columns are useless  , for example timestamp ,  a column that gives the time of execution of the internet traffic  , for sure has nothing to do with defining the application type of an internet traffic thus , we drop it ,same thing for flow ID , it contains values of the source(IP and port) and destination (IP and port) , and there is already a separate column of each of them , since he represent duplicate data , we drop it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValidate = dfValidate.drop(['Flow ID','Timestamp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 82) (23405, 82)\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.shape,dfValidate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain=dfTrain.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    20114\n",
       "4    19590\n",
       "1    19523\n",
       "0    19300\n",
       "5    19179\n",
       "7    19043\n",
       "3    18716\n",
       "2    18644\n",
       "Name: application, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain[\"application\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Protocol',\n",
       " 'Flow Duration',\n",
       " 'Total Fwd Packet',\n",
       " 'Total Bwd packets',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Max',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Fwd Packet Length Mean',\n",
       " 'Fwd Packet Length Std',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Bwd Packet Length Std',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Std',\n",
       " 'Flow IAT Max',\n",
       " 'Flow IAT Min',\n",
       " 'Fwd IAT Total',\n",
       " 'Fwd IAT Mean',\n",
       " 'Fwd IAT Std',\n",
       " 'Fwd IAT Max',\n",
       " 'Fwd IAT Min',\n",
       " 'Bwd IAT Total',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Bwd IAT Max',\n",
       " 'Bwd IAT Min',\n",
       " 'Fwd PSH Flags',\n",
       " 'Bwd PSH Flags',\n",
       " 'Fwd URG Flags',\n",
       " 'Bwd URG Flags',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Fwd Packets/s',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Max',\n",
       " 'Packet Length Mean',\n",
       " 'Packet Length Std',\n",
       " 'Packet Length Variance',\n",
       " 'FIN Flag Count',\n",
       " 'SYN Flag Count',\n",
       " 'RST Flag Count',\n",
       " 'PSH Flag Count',\n",
       " 'ACK Flag Count',\n",
       " 'URG Flag Count',\n",
       " 'CWE Flag Count',\n",
       " 'ECE Flag Count',\n",
       " 'Down/Up Ratio',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'Bwd Segment Size Avg',\n",
       " 'Fwd Bytes/Bulk Avg',\n",
       " 'Fwd Packet/Bulk Avg',\n",
       " 'Fwd Bulk Rate Avg',\n",
       " 'Bwd Bytes/Bulk Avg',\n",
       " 'Bwd Packet/Bulk Avg',\n",
       " 'Bwd Bulk Rate Avg',\n",
       " 'Subflow Fwd Packets',\n",
       " 'Subflow Fwd Bytes',\n",
       " 'Subflow Bwd Packets',\n",
       " 'Subflow Bwd Bytes',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Act Data Pkts',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Active Mean',\n",
       " 'Active Std',\n",
       " 'Active Max',\n",
       " 'Active Min',\n",
       " 'Idle Mean',\n",
       " 'Idle Std',\n",
       " 'Idle Max',\n",
       " 'Idle Min',\n",
       " 'application']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.columns.to_list()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspecting performance so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dfTrain.drop(\"application\",axis=1)\n",
    "y_train = dfTrain.loc[:,[\"application\"]]\n",
    "X_validate = dfValidate.drop(\"application\",axis=1)\n",
    "y_validate = dfValidate.loc[:,[\"application\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before applying feature selection: 0.896432386242256\n",
      "F1-score before applying feature selection: 0.8967646886391679\n",
      "precision-score before applying feature selection: 0.8982620682787179\n",
      "recall-score before applying feature selection: 0.896432386242256\n",
      "confusion-matrix before applying feature selection:\n",
      " [[3172   24    5    1   38    7  295    7]\n",
      " [  13 6396    9    1  163    4  100    0]\n",
      " [   5   14 1637  342   31    1   18  177]\n",
      " [   5    4  207  940    5    2    5   62]\n",
      " [  23  155   18    7 1927    4   63   14]\n",
      " [   3   20    0    0    3 4806    1    0]\n",
      " [ 252  100    7    1   55    4 1500   12]\n",
      " [   1    0   71   45    7    0   13  603]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy before applying feature selection: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score before applying feature selection: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score before applying feature selection: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score before applying feature selection: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix before applying feature selection:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# droping constant features :\n",
    "### Dropping constant features from a dataset can lead to faster computation time, reduce overfitting, improve accuracy, and improve interpretability of the model.\n",
    "### unvariant features  leads the model to \"think\" that there are no differences between classes when we are trying to make him distinguish between them : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Src IP         11003\n",
       "Src Port       44518\n",
       "Dst IP         22984\n",
       "Dst Port       20486\n",
       "Protocol          18\n",
       "               ...  \n",
       "Idle Mean       5519\n",
       "Idle Std       39297\n",
       "Idle Max        4277\n",
       "Idle Min       13108\n",
       "application        8\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique = dfTrain.nunique()\n",
    "num_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = num_unique[num_unique <= 1].index\n",
    "\n",
    "dfTrain=dfTrain.drop(columns_to_drop, axis=1)\n",
    "dfValidate=dfValidate.drop(columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 67) (23405, 67)\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.shape,dfValidate.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance after dropping constant features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after droping constant columns: 0.896218756675924\n",
      "F1-score after droping constant columns: 0.8965857330136279\n",
      "precision-score after droping constant columns: 0.898143752409758\n",
      "recall-score after droping constant columns: 0.896218756675924\n",
      "confusion-matrix after droping constant columns:\n",
      " [[3175   25    8    1   31    7  297    5]\n",
      " [  13 6390    8    2  162    6  105    0]\n",
      " [   6   16 1639  341   29    1   16  177]\n",
      " [   5    4  194  952    6    3    4   62]\n",
      " [  22  153   17    9 1925    5   67   13]\n",
      " [   3   21    0    0    3 4805    1    0]\n",
      " [ 255  102    9    2   53    4 1493   13]\n",
      " [   1    0   75   48    5    0   14  597]]\n"
     ]
    }
   ],
   "source": [
    "X_train = dfTrain.drop(\"application\",axis=1)\n",
    "X_validate = dfValidate.drop(\"application\",axis=1)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy after droping constant columns: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score after droping constant columns: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score after droping constant columns: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score after droping constant columns: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix after droping constant columns:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping one of all mutually highly correlated features to avoid issues with multicollinearity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fwd Packet Length Std', 'Fwd Packet Length Max'), ('Bwd Packet Length Std', 'Bwd Packet Length Max'), ('Flow IAT Max', 'Flow IAT Std'), ('Flow IAT Min', 'Flow IAT Mean'), ('Fwd IAT Total', 'Flow Duration'), ('Fwd IAT Mean', 'Flow IAT Mean'), ('Fwd IAT Max', 'Flow IAT Std'), ('Fwd IAT Max', 'Flow IAT Max'), ('Fwd IAT Min', 'Flow IAT Mean'), ('Fwd IAT Min', 'Fwd IAT Mean'), ('Bwd IAT Total', 'Flow Duration'), ('Bwd IAT Total', 'Fwd IAT Total'), ('Bwd IAT Max', 'Flow IAT Max'), ('Bwd IAT Min', 'Bwd IAT Mean'), ('Fwd Header Length', 'Total Fwd Packet'), ('Bwd Header Length', 'Total Bwd packets'), ('Fwd Packets/s', 'Flow Packets/s'), ('Packet Length Std', 'Packet Length Max'), ('Packet Length Std', 'Packet Length Mean'), ('ACK Flag Count', 'Total Fwd Packet'), ('ACK Flag Count', 'Total Bwd packets'), ('ACK Flag Count', 'Fwd Header Length'), ('ACK Flag Count', 'Bwd Header Length'), ('Average Packet Size', 'Packet Length Mean'), ('Average Packet Size', 'Packet Length Std'), ('Fwd Segment Size Avg', 'Fwd Packet Length Mean'), ('Bwd Segment Size Avg', 'Bwd Packet Length Mean'), ('Bwd Packet/Bulk Avg', 'Total Fwd Packet'), ('Bwd Packet/Bulk Avg', 'Total Bwd packets'), ('Subflow Fwd Bytes', 'Fwd Packet Length Mean'), ('Subflow Fwd Bytes', 'Fwd Segment Size Avg'), ('Subflow Bwd Bytes', 'Bwd Packet Length Mean'), ('Subflow Bwd Bytes', 'Bwd Segment Size Avg'), ('Fwd Act Data Pkts', 'Total Fwd Packet'), ('Fwd Seg Size Min', 'Protocol'), ('Idle Max', 'Idle Mean'), ('Idle Min', 'Idle Mean'), ('Idle Min', 'Idle Max')]\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = dfTrain.corr().abs()\n",
    "\n",
    "high_corr_mask = corr_matrix > 0.8\n",
    "\n",
    "high_corr_features = []\n",
    "for i in range(len(high_corr_mask.columns)):\n",
    "    for j in range(i):\n",
    "        if high_corr_mask.iloc[i, j]:\n",
    "            colname1 = high_corr_mask.columns[i]\n",
    "            colname2 = high_corr_mask.columns[j]\n",
    "            high_corr_features.append((colname1, colname2))\n",
    "\n",
    "print(high_corr_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To choose what column to drop , we will use feature importance provided by a random forest classifier , the one assigned to the lowest importance by the classifier will be dropped :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = dict(zip(X_train.columns, rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr_feature in high_corr_features:\n",
    "    feature1, feature2 = corr_feature\n",
    "    if feature_importance[feature1] > feature_importance[feature2]:\n",
    "        drop_feature = feature2\n",
    "    else:\n",
    "        drop_feature = feature1\n",
    "        \n",
    "    if drop_feature in dfTrain.columns.to_list():\n",
    "        dfTrain.drop(columns=[drop_feature], inplace=True)\n",
    "        dfValidate.drop(columns=[drop_feature], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 41) (23405, 41)\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.shape,dfValidate.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance after dropping one of all mutually highly correlated columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Dropping one of all mutually highly correlated features: 0.8973296304208502\n",
      "F1-score after Dropping one of all mutually highly correlated features: 0.8977920397591332\n",
      "precision-score after Dropping one of all mutually highly correlated features: 0.8993615387749816\n",
      "recall-score after Dropping one of all mutually highly correlated features: 0.8973296304208502\n",
      "confusion-matrix after Dropping one of all mutually highly correlated features:\n",
      " [[3170   26    7    3   31    8  300    4]\n",
      " [  18 6375    8    1  165    5  114    0]\n",
      " [   5   14 1668  313   28    1   23  173]\n",
      " [   4    3  190  958    8    2    5   60]\n",
      " [  21  145   21    9 1920    7   75   13]\n",
      " [   2   19    1    0    3 4808    0    0]\n",
      " [ 259  100    8    2   53    2 1495   12]\n",
      " [   2    0   65   47    5    0   13  608]]\n"
     ]
    }
   ],
   "source": [
    "X_train = dfTrain.drop(\"application\",axis=1)\n",
    "X_validate = dfValidate.drop(\"application\",axis=1)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy after Dropping one of all mutually highly correlated features: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score after Dropping one of all mutually highly correlated features: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score after Dropping one of all mutually highly correlated features: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score after Dropping one of all mutually highly correlated features: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix after Dropping one of all mutually highly correlated features:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recursif feature eliminator (RFE):\n",
    "### RFE is considered a brute force technique ,  at every step , the RFE drops a feature and calculates the efficiency of a model passed to the \"estimator\" argument ,in our case the random forest classifier , if it increases , it will moves to the next iteration , otherwise , it will restore it and drops an other feature until there is only a defined number of features passed to the \"n_features_to_select\" argument, the number of features to drop at each step is passed to the \"step\" argument , in our case we define it as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "rfe = RFE(estimator=clf, n_features_to_select=25, step=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "RFE_selected_features = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Variance',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFE_selected_features= RFE_selected_features.to_list()\n",
    "RFE_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfTrainRFE = dfTrain[RFE_selected_features]\n",
    "dfRFE = dfValidate[RFE_selected_features]\n",
    "\n",
    "print(dfTrainRFE.shape,dfRFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_perf_gain(X_train,X_validate,target,technique):\n",
    "    try:\n",
    "        X_train = X_train.drop(columns=[target])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        X_validate = X_validate.drop(columns=[target])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rfc.predict(X_validate)\n",
    "    accuracy = accuracy_score(y_validate, y_pred)\n",
    "    print(f\"Accuracy with using {technique} technique: {accuracy}\")\n",
    "    F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"F1-score with using {technique} technique: {F1_Score}\")\n",
    "    Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"precision-score with using {technique} technique: {Precision_Score}\")\n",
    "    Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"recall-score with using {technique} technique: {Recall_Score}\")\n",
    "    Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "    print(f\"confusion-matrix with using {technique} technique:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance with features selected by the RFE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using RFE technique: 0.8983550523392437\n",
      "F1-score with using RFE technique: 0.8987659567370357\n",
      "precision-score with using RFE technique: 0.9003590271178014\n",
      "recall-score with using RFE technique: 0.8983550523392437\n",
      "confusion-matrix with using RFE technique:\n",
      " [[3175   25    7    1   31    7  298    5]\n",
      " [  17 6378    8    0  168    4  111    0]\n",
      " [   6   11 1656  328   30    1   15  178]\n",
      " [   3    2  191  968    7    0    3   56]\n",
      " [  20  146   21    6 1936    3   68   11]\n",
      " [   5   18    2    0    3 4805    0    0]\n",
      " [ 264   98    8    2   52    2 1493   12]\n",
      " [   2    0   65   39    5    0   14  615]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainRFE,dfRFE,\"application\",\"RFE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest Feature importance :\n",
    "### here we will only keep features assigned by a high feature importance by a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = dict(zip(X_train.columns, rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_selected_features = [i[0] for i in sorted(feature_importance.items(), key=lambda x:x[1])[::-1]][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Idle Max',\n",
       " 'Src Port',\n",
       " 'Dst Port',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Max',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Duration',\n",
       " 'Bwd Packets/s',\n",
       " 'Dst IP',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Average Packet Size',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'Fwd Header Length',\n",
       " 'Packet Length Variance',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Packet Length Min',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Bwd Header Length',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Subflow Fwd Packets',\n",
       " 'Fwd Packet Length Max']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfTrainRFC = dfTrain[RFC_selected_features]\n",
    "dfRFC = dfValidate[RFC_selected_features]\n",
    "\n",
    "print(dfTrainRFC.shape,dfRFC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using feature importance technique: 0.8993804742576372\n",
      "F1-score with using feature importance technique: 0.8998763512630937\n",
      "precision-score with using feature importance technique: 0.9014145351138501\n",
      "recall-score with using feature importance technique: 0.8993804742576372\n",
      "confusion-matrix with using feature importance technique:\n",
      " [[3184   25    7    2   29    7  291    4]\n",
      " [  15 6376    8    0  167    4  116    0]\n",
      " [   6   10 1671  323   26    1   13  175]\n",
      " [   3    2  195  964    7    1    1   57]\n",
      " [  20  144   20    7 1932    3   74   11]\n",
      " [   2   19    1    0    4 4807    0    0]\n",
      " [ 258   92    8    2   48    2 1511   10]\n",
      " [   2    0   68   46    5    0   14  605]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainRFC,dfRFC,\"application\",\"feature importance\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mutual information gain:\n",
    "### Mutual Information Gain (MIG) is a measure of the amount of information that one random variable X provides about another random variable Y ,the mutual information gain is high when knowing the value of X provides a lot of information about the value of Y, and it is low when knowing the value of X provides little or no information about the value of Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=25)\n",
    "\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "MIC_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Max',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Variance',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC_selected_features=MIC_selected_features.to_list()\n",
    "MIC_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfTrainMIC = dfTrain[MIC_selected_features]\n",
    "dfMIC = dfValidate[MIC_selected_features]\n",
    "\n",
    "print(dfTrainMIC.shape,dfMIC.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance with features selected by the MIC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using MIC technique: 0.8989959410382397\n",
      "F1-score with using MIC technique: 0.8993236312996562\n",
      "precision-score with using MIC technique: 0.9007486613684079\n",
      "recall-score with using MIC technique: 0.8989959410382397\n",
      "confusion-matrix with using MIC technique:\n",
      " [[3183   24    7    1   32   11  286    5]\n",
      " [  20 6389    7    0  161    4  105    0]\n",
      " [   5   12 1656  330   30    2   17  173]\n",
      " [   2    3  195  964    7    2    1   56]\n",
      " [  17  149   25    6 1928    5   72    9]\n",
      " [   2   18    2    0    4 4807    0    0]\n",
      " [ 262   96    8    2   49    1 1500   13]\n",
      " [   2    0   66   41    4    0   13  614]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainMIC,dfMIC,\"application\",\"MIC\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI2 features dependency:\n",
    "### The basic idea behind chi-square-based feature selection is to measure the independence between each feature and the target variable. The intuition is that if a feature is independent of the target variable, it's unlikely to be useful for predicting the target. Conversely, if a feature is dependent on the target variable, it may be a good predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "kbest = SelectKBest(score_func=chi2, k=25)\n",
    "\n",
    "kbest.fit(np.abs(X_train), y_train)\n",
    "\n",
    "CHI2_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd IAT Std',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Variance',\n",
       " 'Bwd Bulk Rate Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Act Data Pkts',\n",
       " 'Idle Std',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHI2_selected_features= CHI2_selected_features.to_list()\n",
    "CHI2_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfTrainCHI2 = dfTrain[CHI2_selected_features]\n",
    "dfCHI2 = dfValidate[CHI2_selected_features]\n",
    "\n",
    "print(dfTrainCHI2.shape,dfCHI2.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance with features selected by CHI2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using CHI2 technique: 0.8963469344157231\n",
      "F1-score with using CHI2 technique: 0.8972462576382563\n",
      "precision-score with using CHI2 technique: 0.8993403904349225\n",
      "recall-score with using CHI2 technique: 0.8963469344157231\n",
      "confusion-matrix with using CHI2 technique:\n",
      " [[3170   21    6    1   33    9  303    6]\n",
      " [  13 6286    9    0  218    4  156    0]\n",
      " [   4   12 1689  306   29    1   11  173]\n",
      " [   3    2  192  966    7    1    3   56]\n",
      " [  19  124   21    8 1938    7   83   11]\n",
      " [   4   22    2    0    4 4801    0    0]\n",
      " [ 251   82    7    1   57    2 1521   10]\n",
      " [   2    0   69   40    6    0   15  608]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainCHI2,dfCHI2,\"application\",\"CHI2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variance (ANOVA):\n",
    "### ANOVA works by comparing the amount of variation between the groups to the amount of variation within the groups, and uses the F-test to determine whether the differences between the groups are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=25)\n",
    "\n",
    "\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "ANOVA_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd IAT Std',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Fwd PSH Flags',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'FIN Flag Count',\n",
       " 'SYN Flag Count',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'Subflow Fwd Packets',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Idle Std',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANOVA_selected_features= ANOVA_selected_features.to_list()\n",
    "ANOVA_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfTrainANOVA = dfTrain[ANOVA_selected_features]\n",
    "dfANOVA = dfValidate[ANOVA_selected_features]\n",
    "\n",
    "print(dfTrainANOVA.shape,dfANOVA.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting performance with features selected by ANOVA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using ANOVA technique: 0.9063020722067934\n",
      "F1-score with using ANOVA technique: 0.9065364978405293\n",
      "precision-score with using ANOVA technique: 0.9073635568380084\n",
      "recall-score with using ANOVA technique: 0.9063020722067934\n",
      "confusion-matrix with using ANOVA technique:\n",
      " [[3186   25    6    1   24    9  294    4]\n",
      " [  15 6425    5    0  139    4   98    0]\n",
      " [   5   12 1757  254   24    2   12  159]\n",
      " [   2    1  175  991    7    2    3   49]\n",
      " [  22  151   21    5 1933    6   63   10]\n",
      " [   1   19    1    1    3 4808    0    0]\n",
      " [ 254  104    6    1   47    2 1504   13]\n",
      " [   1    0   75   37    5    0   14  608]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainANOVA,dfANOVA,\"application\",\"ANOVA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection set of columns between all previous techniques :\n",
    "### we will only keep the features that all previous techniques selected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dst IP', 'Flow Packets/s', 'Src IP', 'Dst Port', 'Flow IAT Max', 'FWD Init Win Bytes', 'Idle Max', 'Bwd Packets/s', 'Src Port'}\n"
     ]
    }
   ],
   "source": [
    "INTERSECTION_features = set(RFE_selected_features).intersection(MIC_selected_features, CHI2_selected_features, ANOVA_selected_features)\n",
    "\n",
    "print(INTERSECTION_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "intesection_features = list(INTERSECTION_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intesection_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting efficiency on the dataset with  the intersected features of all techniques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 9) (23405, 9)\n"
     ]
    }
   ],
   "source": [
    "dfTrainINTER = dfTrain[INTERSECTION_features]\n",
    "dfINTER = dfValidate[INTERSECTION_features]\n",
    "print(dfTrainINTER.shape,dfINTER.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using all technique: 0.8936979277932066\n",
      "F1-score with using all technique: 0.8948765982441874\n",
      "precision-score with using all technique: 0.8970691569792666\n",
      "recall-score with using all technique: 0.8936979277932066\n",
      "confusion-matrix with using all technique:\n",
      " [[3135   18    5    2   38    9  336    6]\n",
      " [  18 6260   12    1  202    4  189    0]\n",
      " [   7    9 1723  288   29    2   12  155]\n",
      " [   2    2  185  991    3    0    2   45]\n",
      " [  41  114   39    8 1910    4   85   10]\n",
      " [   2   21    1    1    8 4800    0    0]\n",
      " [ 246   75   21    1   84    1 1494    9]\n",
      " [   4    1   72   38    4    0   17  604]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfTrainINTER,dfINTER,'application',\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154109, 41)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    20114\n",
       "4    19590\n",
       "1    19523\n",
       "0    19300\n",
       "5    19179\n",
       "7    19043\n",
       "3    18716\n",
       "2    18644\n",
       "Name: application, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain[\"application\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_so_far = ['Src IP',\n",
    " 'Src Port',\n",
    " 'Dst IP',\n",
    " 'Dst Port',\n",
    " 'Fwd Packet Length Min',\n",
    " 'Bwd Packet Length Max',\n",
    " 'Bwd Packet Length Min',\n",
    " 'Bwd Packet Length Mean',\n",
    " 'Flow Packets/s',\n",
    " 'Flow IAT Max',\n",
    " 'Fwd IAT Std',\n",
    " 'Bwd IAT Mean',\n",
    " 'Bwd IAT Std',\n",
    " 'Fwd PSH Flags',\n",
    " 'Bwd Packets/s',\n",
    " 'Packet Length Min',\n",
    " 'FIN Flag Count',\n",
    " 'SYN Flag Count',\n",
    " 'Average Packet Size',\n",
    " 'Fwd Segment Size Avg',\n",
    " 'Subflow Fwd Packets',\n",
    " 'FWD Init Win Bytes',\n",
    " 'Fwd Seg Size Min',\n",
    " 'Idle Std',\n",
    " 'Idle Max']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to summerize , in this section we used different techniques to select features such as:\n",
    "* Domaine knowledge &rarr; F1-score :0.8967646886391679\n",
    "\n",
    "* brute experimentation:\n",
    "\n",
    "    - Recursif feature eliminator (RFE) &rarr; F1-score : 0.89949676619698\n",
    "    \n",
    "* model based techniques:\n",
    "\n",
    "    - Random forest feature importance &rarr; F1-score : 0.8998763512630937\n",
    "    \n",
    "* statistical methods:\n",
    "\n",
    "    - Mutual information gain (MIG) &rarr; F1-score : 0.8993236312996562\n",
    "    \n",
    "    - Correlation &rarr; F1-score : 0.8977920397591332\n",
    "    \n",
    "    - dropping unvariant features &rarr; F1-score : 0.8977920397591332\n",
    "    \n",
    "    - The chi-square feature dependency (CHI2) &rarr; F1-score : 0.8972462576382563\n",
    "    \n",
    "    - intersection set of features &rarr; F1-score : 0.8953174957655806\n",
    "    \n",
    "    - Analysis of variance (ANOVA) &rarr; F1-score : 0.9065364978405293\n",
    "\n",
    "\n",
    "## we can remark that the best performance so far is obtained with the features selected by ANOVA , thus , those features are the ones we will work with in the rest of this journey .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "137936febe64508a75f26b6146f6e1d8233329f1ee95ab18102956da2cf8120f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
