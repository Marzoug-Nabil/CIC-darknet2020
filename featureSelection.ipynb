{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score,precision_score,confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/balancedAppDarknet.csv\")\n",
    "dfv = pd.read_csv(\"data/validation_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping useless or duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv = dfv.drop(['Flow ID','Timestamp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 82) (23405, 82)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape,dfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    20114\n",
       "4    19590\n",
       "1    19523\n",
       "0    19300\n",
       "5    19179\n",
       "7    19043\n",
       "3    18716\n",
       "2    18644\n",
       "Name: application, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"application\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Protocol',\n",
       " 'Flow Duration',\n",
       " 'Total Fwd Packet',\n",
       " 'Total Bwd packets',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Max',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Fwd Packet Length Mean',\n",
       " 'Fwd Packet Length Std',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Bwd Packet Length Std',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Std',\n",
       " 'Flow IAT Max',\n",
       " 'Flow IAT Min',\n",
       " 'Fwd IAT Total',\n",
       " 'Fwd IAT Mean',\n",
       " 'Fwd IAT Std',\n",
       " 'Fwd IAT Max',\n",
       " 'Fwd IAT Min',\n",
       " 'Bwd IAT Total',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Bwd IAT Max',\n",
       " 'Bwd IAT Min',\n",
       " 'Fwd PSH Flags',\n",
       " 'Bwd PSH Flags',\n",
       " 'Fwd URG Flags',\n",
       " 'Bwd URG Flags',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Fwd Packets/s',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Max',\n",
       " 'Packet Length Mean',\n",
       " 'Packet Length Std',\n",
       " 'Packet Length Variance',\n",
       " 'FIN Flag Count',\n",
       " 'SYN Flag Count',\n",
       " 'RST Flag Count',\n",
       " 'PSH Flag Count',\n",
       " 'ACK Flag Count',\n",
       " 'URG Flag Count',\n",
       " 'CWE Flag Count',\n",
       " 'ECE Flag Count',\n",
       " 'Down/Up Ratio',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'Bwd Segment Size Avg',\n",
       " 'Fwd Bytes/Bulk Avg',\n",
       " 'Fwd Packet/Bulk Avg',\n",
       " 'Fwd Bulk Rate Avg',\n",
       " 'Bwd Bytes/Bulk Avg',\n",
       " 'Bwd Packet/Bulk Avg',\n",
       " 'Bwd Bulk Rate Avg',\n",
       " 'Subflow Fwd Packets',\n",
       " 'Subflow Fwd Bytes',\n",
       " 'Subflow Bwd Packets',\n",
       " 'Subflow Bwd Bytes',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Act Data Pkts',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Active Mean',\n",
       " 'Active Std',\n",
       " 'Active Max',\n",
       " 'Active Min',\n",
       " 'Idle Mean',\n",
       " 'Idle Std',\n",
       " 'Idle Max',\n",
       " 'Idle Min',\n",
       " 'application']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(\"application\",axis=1)\n",
    "y_train = df.loc[:,[\"application\"]]\n",
    "X_validate = dfv.drop(\"application\",axis=1)\n",
    "y_validate = dfv.loc[:,[\"application\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before applying feature selection: 0.896432386242256\n",
      "F1-score before applying feature selection: 0.8967646886391679\n",
      "precision-score before applying feature selection: 0.8982620682787179\n",
      "recall-score before applying feature selection: 0.896432386242256\n",
      "confusion-matrix before applying feature selection:\n",
      " [[3172   24    5    1   38    7  295    7]\n",
      " [  13 6396    9    1  163    4  100    0]\n",
      " [   5   14 1637  342   31    1   18  177]\n",
      " [   5    4  207  940    5    2    5   62]\n",
      " [  23  155   18    7 1927    4   63   14]\n",
      " [   3   20    0    0    3 4806    1    0]\n",
      " [ 252  100    7    1   55    4 1500   12]\n",
      " [   1    0   71   45    7    0   13  603]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy before applying feature selection: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score before applying feature selection: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score before applying feature selection: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score before applying feature selection: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix before applying feature selection:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# droping constant features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Src IP         11003\n",
       "Src Port       44518\n",
       "Dst IP         22984\n",
       "Dst Port       20486\n",
       "Protocol          18\n",
       "               ...  \n",
       "Idle Mean       5519\n",
       "Idle Std       39297\n",
       "Idle Max        4277\n",
       "Idle Min       13108\n",
       "application        8\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique = df.nunique()\n",
    "num_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = num_unique[num_unique <= 1].index\n",
    "\n",
    "df=df.drop(columns_to_drop, axis=1)\n",
    "dfv=dfv.drop(columns_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 67) (23405, 67)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape,dfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after droping constant columns: 0.896218756675924\n",
      "F1-score after droping constant columns: 0.8965857330136279\n",
      "precision-score after droping constant columns: 0.898143752409758\n",
      "recall-score after droping constant columns: 0.896218756675924\n",
      "confusion-matrix after droping constant columns:\n",
      " [[3175   25    8    1   31    7  297    5]\n",
      " [  13 6390    8    2  162    6  105    0]\n",
      " [   6   16 1639  341   29    1   16  177]\n",
      " [   5    4  194  952    6    3    4   62]\n",
      " [  22  153   17    9 1925    5   67   13]\n",
      " [   3   21    0    0    3 4805    1    0]\n",
      " [ 255  102    9    2   53    4 1493   13]\n",
      " [   1    0   75   48    5    0   14  597]]\n"
     ]
    }
   ],
   "source": [
    "X_train = df.drop(\"application\",axis=1)\n",
    "X_validate = dfv.drop(\"application\",axis=1)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy after droping constant columns: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score after droping constant columns: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score after droping constant columns: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score after droping constant columns: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix after droping constant columns:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping one of all mutually highly correlated features to avoid issues with multicollinearity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Fwd Packet Length Std', 'Fwd Packet Length Max'), ('Bwd Packet Length Std', 'Bwd Packet Length Max'), ('Flow IAT Max', 'Flow IAT Std'), ('Flow IAT Min', 'Flow IAT Mean'), ('Fwd IAT Total', 'Flow Duration'), ('Fwd IAT Mean', 'Flow IAT Mean'), ('Fwd IAT Max', 'Flow IAT Std'), ('Fwd IAT Max', 'Flow IAT Max'), ('Fwd IAT Min', 'Flow IAT Mean'), ('Fwd IAT Min', 'Fwd IAT Mean'), ('Bwd IAT Total', 'Flow Duration'), ('Bwd IAT Total', 'Fwd IAT Total'), ('Bwd IAT Max', 'Flow IAT Max'), ('Bwd IAT Min', 'Bwd IAT Mean'), ('Fwd Header Length', 'Total Fwd Packet'), ('Bwd Header Length', 'Total Bwd packets'), ('Fwd Packets/s', 'Flow Packets/s'), ('Packet Length Std', 'Packet Length Max'), ('Packet Length Std', 'Packet Length Mean'), ('ACK Flag Count', 'Total Fwd Packet'), ('ACK Flag Count', 'Total Bwd packets'), ('ACK Flag Count', 'Fwd Header Length'), ('ACK Flag Count', 'Bwd Header Length'), ('Average Packet Size', 'Packet Length Mean'), ('Average Packet Size', 'Packet Length Std'), ('Fwd Segment Size Avg', 'Fwd Packet Length Mean'), ('Bwd Segment Size Avg', 'Bwd Packet Length Mean'), ('Bwd Packet/Bulk Avg', 'Total Fwd Packet'), ('Bwd Packet/Bulk Avg', 'Total Bwd packets'), ('Subflow Fwd Bytes', 'Fwd Packet Length Mean'), ('Subflow Fwd Bytes', 'Fwd Segment Size Avg'), ('Subflow Bwd Bytes', 'Bwd Packet Length Mean'), ('Subflow Bwd Bytes', 'Bwd Segment Size Avg'), ('Fwd Act Data Pkts', 'Total Fwd Packet'), ('Fwd Seg Size Min', 'Protocol'), ('Idle Max', 'Idle Mean'), ('Idle Min', 'Idle Mean'), ('Idle Min', 'Idle Max')]\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "\n",
    "high_corr_mask = corr_matrix > 0.8\n",
    "\n",
    "high_corr_features = []\n",
    "for i in range(len(high_corr_mask.columns)):\n",
    "    for j in range(i):\n",
    "        if high_corr_mask.iloc[i, j]:\n",
    "            colname1 = high_corr_mask.columns[i]\n",
    "            colname2 = high_corr_mask.columns[j]\n",
    "            high_corr_features.append((colname1, colname2))\n",
    "\n",
    "print(high_corr_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to choose what column to drop , we will use feature importance provided by a random forest classifier , the one assigned to the lowest importance by the classifier will be dropped :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = dict(zip(X_train.columns, rf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr_feature in high_corr_features:\n",
    "    feature1, feature2 = corr_feature\n",
    "    if feature_importance[feature1] > feature_importance[feature2]:\n",
    "        drop_feature = feature2\n",
    "    else:\n",
    "        drop_feature = feature1\n",
    "        \n",
    "    if drop_feature in df.columns.to_list():\n",
    "        df.drop(columns=[drop_feature], inplace=True)\n",
    "        dfv.drop(columns=[drop_feature], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 41) (23405, 41)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape,dfv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Dropping one of all mutually highly correlated features: 0.8973296304208502\n",
      "F1-score after Dropping one of all mutually highly correlated features: 0.8977920397591332\n",
      "precision-score after Dropping one of all mutually highly correlated features: 0.8993615387749816\n",
      "recall-score after Dropping one of all mutually highly correlated features: 0.8973296304208502\n",
      "confusion-matrix after Dropping one of all mutually highly correlated features:\n",
      " [[3170   26    7    3   31    8  300    4]\n",
      " [  18 6375    8    1  165    5  114    0]\n",
      " [   5   14 1668  313   28    1   23  173]\n",
      " [   4    3  190  958    8    2    5   60]\n",
      " [  21  145   21    9 1920    7   75   13]\n",
      " [   2   19    1    0    3 4808    0    0]\n",
      " [ 259  100    8    2   53    2 1495   12]\n",
      " [   2    0   65   47    5    0   13  608]]\n"
     ]
    }
   ],
   "source": [
    "X_train = df.drop(\"application\",axis=1)\n",
    "X_validate = dfv.drop(\"application\",axis=1)\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_validate)\n",
    "accuracy = accuracy_score(y_validate, y_pred)\n",
    "print(f\"Accuracy after Dropping one of all mutually highly correlated features: {accuracy}\")\n",
    "F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"F1-score after Dropping one of all mutually highly correlated features: {F1_Score}\")\n",
    "Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"precision-score after Dropping one of all mutually highly correlated features: {Precision_Score}\")\n",
    "Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "print(f\"recall-score after Dropping one of all mutually highly correlated features: {Recall_Score}\")\n",
    "Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "print(f\"confusion-matrix after Dropping one of all mutually highly correlated features:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recursif feature eliminator (RFE):\n",
    "### at every step , the RFE drops a feature and calculates the efficiency of a model passed to the \"estimator\" argument ,in our case the random forest classifier , if it increases , it will moves to the next iteration , otherwise , it will restore it and drops an other feature until there is only a defined number of features passed to the \"n_features_to_select\" argument, the number of features to drop at each step is passed to the \"step\" argument , in our case we define it as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "rfe = RFE(estimator=clf, n_features_to_select=25, step=1)\n",
    "\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "RFE_selected_features = X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Variance',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFE_selected_features= RFE_selected_features.to_list()\n",
    "RFE_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfRFE = df[RFE_selected_features]\n",
    "dfvRFE = dfv[RFE_selected_features]\n",
    "\n",
    "print(dfRFE.shape,dfvRFE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_perf_gain(X_train,X_validate,target,technique):\n",
    "    try:\n",
    "        X_train = X_train.drop(columns=[target])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        X_validate = X_validate.drop(columns=[target])\n",
    "    except KeyError:\n",
    "        pass\n",
    "    rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rfc.predict(X_validate)\n",
    "    accuracy = accuracy_score(y_validate, y_pred)\n",
    "    print(f\"Accuracy with using {technique} technique: {accuracy}\")\n",
    "    F1_Score = f1_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"F1-score with using {technique} technique: {F1_Score}\")\n",
    "    Precision_Score = precision_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"precision-score with using {technique} technique: {Precision_Score}\")\n",
    "    Recall_Score = recall_score(y_validate,y_pred,average='weighted')\n",
    "    print(f\"recall-score with using {technique} technique: {Recall_Score}\")\n",
    "    Confusion_Matrix = confusion_matrix(y_validate,y_pred)\n",
    "    print(f\"confusion-matrix with using {technique} technique:\\n {Confusion_Matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using RFE technique: 0.8990386669515061\n",
      "F1-score with using RFE technique: 0.89949676619698\n",
      "precision-score with using RFE technique: 0.9011063391757556\n",
      "recall-score with using RFE technique: 0.8990386669515061\n",
      "confusion-matrix with using RFE technique:\n",
      " [[3181   25    8    1   32    7  289    6]\n",
      " [  14 6372    9    1  167    4  119    0]\n",
      " [   8   12 1663  324   25    1   15  177]\n",
      " [   3    3  188  969    8    1    3   55]\n",
      " [  17  141   23    6 1940    3   72    9]\n",
      " [   3   17    1    1    3 4808    0    0]\n",
      " [ 262  101    9    3   47    1 1497   11]\n",
      " [   2    0   62   45    5    0   14  612]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfRFE,dfvRFE,\"application\",\"RFE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mutual information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=25)\n",
    "\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "MIC_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Fwd Packet Length Max',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'Packet Length Variance',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC_selected_features=MIC_selected_features.to_list()\n",
    "MIC_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfMIC = df[MIC_selected_features]\n",
    "dfvMIC = dfv[MIC_selected_features]\n",
    "\n",
    "print(dfMIC.shape,dfvMIC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using MIC technique: 0.8989959410382397\n",
      "F1-score with using MIC technique: 0.8993236312996562\n",
      "precision-score with using MIC technique: 0.9007486613684079\n",
      "recall-score with using MIC technique: 0.8989959410382397\n",
      "confusion-matrix with using MIC technique:\n",
      " [[3183   24    7    1   32   11  286    5]\n",
      " [  20 6389    7    0  161    4  105    0]\n",
      " [   5   12 1656  330   30    2   17  173]\n",
      " [   2    3  195  964    7    2    1   56]\n",
      " [  17  149   25    6 1928    5   72    9]\n",
      " [   2   18    2    0    4 4807    0    0]\n",
      " [ 262   96    8    2   49    1 1500   13]\n",
      " [   2    0   66   41    4    0   13  614]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfMIC,dfvMIC,\"application\",\"MIC\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHI2 features dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "kbest = SelectKBest(score_func=chi2, k=25)\n",
    "\n",
    "kbest.fit(np.abs(X_train), y_train)\n",
    "\n",
    "CHI2_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Flow Duration',\n",
       " 'Total Length of Fwd Packet',\n",
       " 'Total Length of Bwd Packet',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Flow Bytes/s',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Mean',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd IAT Std',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Fwd Header Length',\n",
       " 'Bwd Header Length',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Variance',\n",
       " 'Bwd Bulk Rate Avg',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Bwd Init Win Bytes',\n",
       " 'Fwd Act Data Pkts',\n",
       " 'Idle Std',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHI2_selected_features= CHI2_selected_features.to_list()\n",
    "CHI2_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfCHI2 = df[CHI2_selected_features]\n",
    "dfvCHI2 = dfv[CHI2_selected_features]\n",
    "\n",
    "print(dfCHI2.shape,dfvCHI2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using CHI2 technique: 0.8963469344157231\n",
      "F1-score with using CHI2 technique: 0.8972462576382563\n",
      "precision-score with using CHI2 technique: 0.8993403904349225\n",
      "recall-score with using CHI2 technique: 0.8963469344157231\n",
      "confusion-matrix with using CHI2 technique:\n",
      " [[3170   21    6    1   33    9  303    6]\n",
      " [  13 6286    9    0  218    4  156    0]\n",
      " [   4   12 1689  306   29    1   11  173]\n",
      " [   3    2  192  966    7    1    3   56]\n",
      " [  19  124   21    8 1938    7   83   11]\n",
      " [   4   22    2    0    4 4801    0    0]\n",
      " [ 251   82    7    1   57    2 1521   10]\n",
      " [   2    0   69   40    6    0   15  608]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfCHI2,dfvCHI2,\"application\",\"CHI2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNOVA features dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "kbest = SelectKBest(score_func=f_classif, k=25)\n",
    "\n",
    "\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "ANNOVA_selected_features = X_train.columns[kbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Src IP',\n",
       " 'Src Port',\n",
       " 'Dst IP',\n",
       " 'Dst Port',\n",
       " 'Fwd Packet Length Min',\n",
       " 'Bwd Packet Length Max',\n",
       " 'Bwd Packet Length Min',\n",
       " 'Bwd Packet Length Mean',\n",
       " 'Flow Packets/s',\n",
       " 'Flow IAT Max',\n",
       " 'Fwd IAT Std',\n",
       " 'Bwd IAT Mean',\n",
       " 'Bwd IAT Std',\n",
       " 'Fwd PSH Flags',\n",
       " 'Bwd Packets/s',\n",
       " 'Packet Length Min',\n",
       " 'FIN Flag Count',\n",
       " 'SYN Flag Count',\n",
       " 'Average Packet Size',\n",
       " 'Fwd Segment Size Avg',\n",
       " 'Subflow Fwd Packets',\n",
       " 'FWD Init Win Bytes',\n",
       " 'Fwd Seg Size Min',\n",
       " 'Idle Std',\n",
       " 'Idle Max']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANNOVA_selected_features= ANNOVA_selected_features.to_list()\n",
    "ANNOVA_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 25) (23405, 25)\n"
     ]
    }
   ],
   "source": [
    "dfANNOVA = df[ANNOVA_selected_features]\n",
    "dfvANNOVA = dfv[ANNOVA_selected_features]\n",
    "\n",
    "print(dfANNOVA.shape,dfvANNOVA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using ANNOVA technique: 0.9063020722067934\n",
      "F1-score with using ANNOVA technique: 0.9065364978405293\n",
      "precision-score with using ANNOVA technique: 0.9073635568380084\n",
      "recall-score with using ANNOVA technique: 0.9063020722067934\n",
      "confusion-matrix with using ANNOVA technique:\n",
      " [[3186   25    6    1   24    9  294    4]\n",
      " [  15 6425    5    0  139    4   98    0]\n",
      " [   5   12 1757  254   24    2   12  159]\n",
      " [   2    1  175  991    7    2    3   49]\n",
      " [  22  151   21    5 1933    6   63   10]\n",
      " [   1   19    1    1    3 4808    0    0]\n",
      " [ 254  104    6    1   47    2 1504   13]\n",
      " [   1    0   75   37    5    0   14  608]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfANNOVA,dfvANNOVA,\"application\",\"ANNOVA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overall best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Flow Packets/s', 'FWD Init Win Bytes', 'Dst IP', 'Flow IAT Max', 'Src IP', 'Dst Port', 'Bwd Packets/s', 'Src Port', 'Idle Max'}\n"
     ]
    }
   ],
   "source": [
    "INTERSECTION_features = set(RFE_selected_features).intersection(MIC_selected_features, CHI2_selected_features, ANNOVA_selected_features)\n",
    "\n",
    "print(INTERSECTION_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = list(INTERSECTION_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154109, 9) (23405, 9)\n"
     ]
    }
   ],
   "source": [
    "dfINTER = df[INTERSECTION_features]\n",
    "dfvINTER = dfv[INTERSECTION_features]\n",
    "print(dfINTER.shape,dfvINTER.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with using all technique: 0.8942106387524034\n",
      "F1-score with using all technique: 0.8953174957655806\n",
      "precision-score with using all technique: 0.8974188056000503\n",
      "recall-score with using all technique: 0.8942106387524034\n",
      "confusion-matrix with using all technique:\n",
      " [[3136   19    7    2   39    7  333    6]\n",
      " [  21 6265   10    1  207    3  179    0]\n",
      " [   6   10 1721  287   30    2   14  155]\n",
      " [   2    1  185  992    2    0    2   46]\n",
      " [  42  115   39    6 1909    5   85   10]\n",
      " [   2   22    1    1    6 4801    0    0]\n",
      " [ 246   78   18    0   83    0 1499    7]\n",
      " [   4    1   71   38    5    0   15  606]]\n"
     ]
    }
   ],
   "source": [
    "inspect_perf_gain(dfINTER,dfvINTER,'application',\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154109, 41)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    20114\n",
       "4    19590\n",
       "1    19523\n",
       "0    19300\n",
       "5    19179\n",
       "7    19043\n",
       "3    18716\n",
       "2    18644\n",
       "Name: application, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"application\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "137936febe64508a75f26b6146f6e1d8233329f1ee95ab18102956da2cf8120f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
